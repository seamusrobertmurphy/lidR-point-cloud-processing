---
title: "Script Review: '14_lidR-Processing_to_Git'"
author: "SRM-LQ"
date: "04/02/2022"
output: 
  github_document:
    toc: TRUE
    toc_depth: 5
    number_sections: TRUE
  zotero: TRUE
  bibliography: references.bib   
---

```{r setup, echo=FALSE, message=FALSE,warning=FALSE, error=FALSE}
library(lidR)
library(mapview)
library(rgl)
library(pandocfilters)
library(rmarkdown)
library(formatR)
library(gitignore)
library(tinytex)
library(knitr)
library(raster)
knit_hooks$set(webgl = hook_webgl)
knit_hooks$set(rgl.static = hook_rgl)
knitr::opts_chunk$set(echo = TRUE, cache = TRUE, warning=FALSE, error=FALSE, message = FALSE)
set.seed(23)
```

## Action {.unnumbered}

This following indcludes R Markdown documentation of the LiDAR processing steps taken to derive landscape metrics and raster covariates from a continuous point cloud using the lidR package. This report and literate programming, along with its virtual environment were are stored in the github repository here: ["13_lidR_PointCloud_Processing](https://github.com/seamusrobertmurphy/13_lidR_PointCloud_Processing.git).

# Import LiDAR

LiDAR downloads for the Ahbau region were imported as zip files and unpacked from their top-directory and subdirectory folders using the unzip function. I could not find any published R packages that deal with .7z archive files. Instead custom-written function was adopted from the RAMP project. This was done with the following code chunk:

```{r, echo=TRUE, eval=FALSE}
zip_file_ahbau = ("./14_LiDR-Processing_GitRepo/Data/Ahbau.zip")
zip_dir_ahbau_top = ("./14_LiDR-Processing_GitRepo/Data/")
unzip(zip_file_ahbau, 
      exdir = zip_dir_ahbau_top, 
      overwrite = TRUE)
zip_dir_ahbau_sub = ("./14_LiDR-Processing_GitRepo/Data/Ahbau/Las_v12_ASPRS")
zip_file_ahbau_sub = list.files(
  zip_dir_ahbau_sub,
  full.names = T,
  recursive = F,
  pattern = '.7z$')
 Write RAMP function and extract
un7zip = function(archive, where) {
  archive <- normalizePath(archive)
  current_path <- setwd(where)
  system(paste("7zr x", archive, sep = " "))
  setwd(current_path) }
un7zip(zip_file_ahbau_sub, zip_dir_ahbau_top)
```

# Read, Validate, and Assemble LiDAR Collection

LiDAR data for the Ahbau region included 311 tiles. Tiles were assembled, imported and processed as a LAS collection object using the *LAScatalog* Engine. Initial validation of catalog tiling reported overlapping areas. As per PI recommendations, retiling and rebuffering was implemented to remove potential duplicates with new chunk sizing ok 1km each,  *readALSLAScatalog* function, which allowed settings for chunk processing, spatial indexing, buffering and duplicate cleaning. Parameters were calibrated to conduct retiling and remove duplicates generated by tiles  This was confirmed in validation reports below.

```{r, eval=TRUE}
las_ctg_ahbau = readALSLAScatalog("./Data/Ahbau/Las_v12_ASPRS/", select = "xyz",)
crs(las_ctg_ahbau) = 3005
las_check(las_ctg_ahbau)
plot(las_ctg_ahbau)
```

Catalog indexing and chunk processing was attempted first time around using the *catalog_laxindex* and the *catalog_retile* operations. This was a little more sluggish and buggy, and only relies on the internal lidR tools of *readALSLAScatalog* that was faster. The *readALSLAScatalog* function allows calibrating chunk processing, rebuffering, indexing, and filtering while reading in. According to lidR manual, 'catalogs with files that overlap each other are not natively supported by lidR. When encountering such datasets the user should always filter any overlaps if possible' (cite: pg #no.). To avoid edge artifacts, reccommended buffering was left at 10m and the '-drop_overlap' filter was applied. 

```{r, eval=FALSE}
las_ctg_ahbau_indexed = readALSLAScatalog("./Data/Ahbau/Las_v12_ASPRS/", 
                                          select = 'xyz', 
                                          filter='-drop_overlap', 
                                          chunk_size = 1000, 
                                          chunk_buffer = 10)

opt_output_files(las_ctg_ahbau_indexed) = paste0(
  tempdir(), "./Data/las_ctg_ahbau_indexed")
filter_duplicates(las_ctg_ahbau_indexed)
crs(las_ctg_ahbau_indexed) = 3005
is.indexed(las_ctg_ahbau_indexed)
las_check(las_ctg_ahbau_indexed)
plot(las_ctg_ahbau_indexed, chunk = TRUE)
```

```{r, eval=TRUE, echo=FALSE, rgl.static=TRUE}
las_ctg_ahbau_indexed = readALSLAScatalog("./Data/Ahbau/Las_v12_ASPRS/", 
                                          select = 'xyz', 
                                          filter='-drop_overlap', 
                                          chunk_size = 1000, 
                                          chunk_buffer = 10)

opt_output_files(las_ctg_ahbau_indexed) = paste0(tempdir(), "./Data/las_ctg_ahbau_indexed")
crs(las_ctg_ahbau_indexed) = 3005
is.indexed(las_ctg_ahbau_indexed)
las_check(las_ctg_ahbau_indexed)
plot(las_ctg_ahbau_indexed, chunk = TRUE)

# deprecated functions
#opt_chunk_buffer(las_ctg_ahbau) = 10
#opt_chunk_size(las_ctg_ahbau) = 1000
#opt_select(las_ctg_ahbau) = "xyz"
#opt_filter("-drop_overlap")
#index(las_ctg_ahbau) = 
#las_ctg_ahbau = lidR:::catalog_laxindex(las_ctg_ahbau)
#las_ctg_ahbau_indexed = readALSLAScatalog("./Data/las_ctg_ahbau_indexed")

# Retiling pipeline
#opt_output_files(las_ctg_ahbau_indexed) <- paste0(tempdir(), "./Data/las_ctg_ahbau_retiled")
#opt_chunk_buffer(las_ctg_ahbau_indexed) = 0
#opt_chunk_size(las_ctg_ahbau_indexed) = 1000
#las_ctg_ahbau_retiled = catalog_retile(las_ctg_ahbau_indexed)
#crs(las_ctg_ahbau_indexed) = 3005
#plot(las_ctg_ahbau_retiled, chunk = TRUE)
```

For visualization purposes, a single las tile '093g030122ne" was loaded, processed and plotted. All subsequent illustrations of processing operations were rendered using this tile chunk.

```{r, rgl.static=TRUE, echo=TRUE}
las_tile_ahbau = readLAS("./Data/Ahbau/Las_v12_ASPRS/093g030122ne.las", select = 'xyz')
crs(las_tile_ahbau) = 3005
filter_duplicates(las_tile_ahbau)
plot(las_tile_ahbau, bg = "white")
```

# Classification of Ground Points

Classification of ground points was implemented twice comparing system running time and data voids between the 'csf()' Cloth Simulation Filter algorithm [\@zhang2016] and the 'pmf()' Progressive Morphological Filter algorithm [\@zhang2003]. To cover all potnetial eventualities, the RCSF packaged was installed from CRAN source file and loaded into the github repository ready for virtual environment cloning (see link in Action section). Though this package is not a package dependent, just seems to facilitate better with fewer bugs popping up.

The Cloth Simulation Filter algorithm was fitted with three parameters in order to account for variable topography across the study site and to reduce errors during any potential post-processing. This included the sloop_smooth that was applied over a cloth resolution of 10cm at a rigidness factor of 1.

```{r, eval=FALSE}
library(RCSF)
opt_output_files(las_ctg_ahbau_indexed) =  paste0(tempdir(), "./Data/las_ctg_ahbau_csf")
las_ctg_ahbau_csf = classify_ground(las_ctg_ahbau_indexed, csf(sloop_smooth=TRUE, 0.5, 1))
las_tile_ahbau_csf = classify_ground(las_tile_ahbau, csf(sloop_smooth=TRUE, 0.5, 1))
plot(las_tile_ahbau_csf, color = "Classification", bg = "white") 
```

```{r, echo=FALSE, rgl.static=TRUE, cache=TRUE}
las_tile_ahbau_csf = classify_ground(las_tile_ahbau, csf(sloop_smooth=TRUE, 0.5, 1))
plot(las_tile_ahbau_csf, color = "Classification", bg = "white") 
```

## Progressive Morphological Filter

The Progressive Morphological Filter algorithm was tuned using the 'util_makeZhangParam()' method, which generated a list of candidate parameters for testing window size and threshold. This internal function simply provides a sequence of parameters that match those in the original paper [\@zhang2003].

```{r, eval=FALSE}
opt_output_files(las_ctg_ahbau_indexed) =  paste0(tempdir(), "./Data/las_ctg_ahbau_pmf")
util_makeZhangParam()
las_ctg_ahbau_pmf = classify_ground(las_ctg_ahbau_indexed, pmf(seq(5, 9, 13), seq(3, 3, 3)))
las_tile_ahbau_pmf = classify_ground(las_tile_ahbau, pmf(seq(5, 9, 13), seq(3, 3, 3)))
plot(las_tile_ahbau_pmf, color = "Classification", bg = "white") 
```

```{r, rgl.static=TRUE, echo=FALSE}
plot(las_tile_ahbau_pmf, color = "Classification", bg = "white") 
```


# Classification and Removal of Photon Noise

Classification of photon noise was applied using the 'sor' Statistical Outlier Removal' algorithm. This was fitted with a neighbourhood sample of 21 points and a multiplier of 4 in consideration of mean point density (21/m^2^) and a target resolution of 1m. Default settings are otherwise set to k=10 and m=3. 

```{r, eval=FALSE}
opt_output_files(las_ctg_ahbau_csf) <- paste0(tempdir(), "./Data/las_ctg_ahbau_csf_so")
opt_output_files(las_ctg_ahbau_csf_so) <- paste0(tempdir(), "./Data/las_ctg_ahbau_csf_sor")
las_ctg_ahbau_csf_so = classify_noise(las_ctg_ahbau_csf, sor(k=21, m=4))
las_ctg_ahbau_csf_sor = filter_poi(las_ctg_ahbau_csf_so, Classification != LASNOISE)

opt_output_files(las_ctg_ahbau_pmf) <- paste0(tempdir(), "./Data/las_ctg_ahbau_pmf_so")
opt_output_files(las_ctg_ahbau_pmf_so) <- paste0(tempdir(), "./Data/las_ctg_ahbau_pmf_sor")
las_ctg_ahbau_pmf_so = classify_noise(las_ctg_ahbau_pmf, sor(k=21, m=4))
las_ctg_ahbau_pmf_sor = filter_poi(las_ctg_ahbau_pmf_so, Classification != LASNOISE)

las_tile_ahbau_csf_so = classify_noise(las_tile_ahbau_csf, sor(k=21, m=4))
las_tile_ahbau_pmf_so = classify_noise(las_tile_ahbau_pmf, sor(k=21, m=4))
plot(las_tile_ahbau_csf_so, color = "Classification", bg = "white") 
plot(las_tile_ahbau_pmf_so, color = "Classification", bg = "white") 
las_tile_ahbau_csf_sor = filter_poi(las_tile_ahbau_csf_so, Classification != LASNOISE)
las_tile_ahbau_pmf_sor = filter_poi(las_tile_ahbau_pmf_so, Classification != LASNOISE)
```

```{r, rgl.static=TRUE, echo=FALSE}
plot(las_tile_ahbau_csf_so, color = "Classification", bg = "white") 
plot(las_tile_ahbau_pmf_so, color = "Classification", bg = "white") 
```

# Digital Terrain Model

Prior to height normalization, the cleaned and classified ground points were used to derive a digital terrain model by applying the Inverse Distance Weighting algorithm [\@tu2020]. As per PI's guidance, the Inverse Distance Weighting algorithm was chosen for its improved running time and its sensitivity to lake anomalies. This was implemented twice to compare between digital terrain models derived from 'CSF' and 'PMF' classificaitons. Parameters were set including default maximum radius of 50 units, with a queen neighbourhood and an inverse distance weighting power of 2. 

```{r, eval=FALSE}
library(terra)
opt_output_files(las_ctg_ahbau_sor_csf) = paste0(tempdir(), "./Data/las_ctg_ahbau_sor_csf_dtim")
opt_output_files(las_ctg_ahbau_sor_pmf) = paste0(tempdir(), "./Data/las_ctg_ahbau_sor_pmf_dtm")
las_ctg_ahbau_sor_csf_dtm = rasterize_terrain(las_ctg_ahbau_sor_csf, knnidw(21, 4, 50))
las_ctg_ahbau_sor_pmf_dtm = rasterize_terrain(las_ctg_ahbau_sor_pmf, knnidw(21, 2, 50))

las_tile_ahbau_sor_csf_dtm = grid_terrain(
  las_tile_ahbau_sor_csf, 1, knnidw(k = 10L, p = 2, rmax = 50))
las_tile_ahbau_sor_pmf_dtm = grid_terrain(
  las_tile_ahbau_sor_pmf, 1, knnidw(k = 10, p = 2, rmax = 50))
las_tile_ahbau_sor_csf_dtm_plot = plot_dtm3d(
  las_tile_ahbau_sor_csf_dtm, bg = "white") 
las_tile_ahbau_sor_pmf_dtm_plot = plot_dtm3d(
  las_tile_ahbau_sor_pmf_dtm, bg = "white") 
```

```{r, echo=FALSE, rgl.static=TRUE}
las_tile_ahbau_sor_csf_dtm_plot = plot_dtm3d(
  las_tile_ahbau_sor_csf_dtm, bg = "white") 
las_tile_ahbau_sor_pmf_dtm_plot = plot_dtm3d(
  las_tile_ahbau_sor_pmf_dtm, bg = "white") 
```

# Height Normalization of Point Cloud

```{r, eval=FALSE}
opt_output_files(ctg) <-  paste0(tempdir(), "/{*}_norm")
las_ctg_ahbau_sor_csf_norm <- normalize_height(
  las_ctg_ahbau_sor_csf, knnidw())
las_ctg_ahbau_sor_pmf_norm <- normalize_height(
  las_ctg_ahbau_sor_pmf, knnidw())

las_tile_ahbau_sor_csf_norm <- normalize_height(
  las_tile_ahbau_sor_csf, knnidw())
las_tile_ahbau_sor_pmf_norm <- normalize_height(
  las_tile_ahbau_sor_pmf_dtm, knnidw())
plot(las_tile_ahbau_sor_csf_norm, bg = "white")
plot(las_tile_ahbau_sor_pmf_norm, bg = "white")
```

```{r, echo=FALSE, rgl.static=TRUE}
plot(las_tile_ahbau_sor_csf_norm, bg = "white")
plot(las_tile_ahbau_sor_pmf_norm, bg = "white")
```

# Digital Surface Model

## Triangulation of DSM

## Pit-free Algorithm

## Post-processing of Canopy Height Model

# Inndividual Tree Detection and Segmentation

# Derive Metrics at the Point Cloud Level
